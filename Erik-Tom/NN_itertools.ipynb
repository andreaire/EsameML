{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def fix_random(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_random(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e8f32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe86f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train set:  108\n",
      "Numebr of test set:  30\n",
      "Number of validation set:  12\n"
     ]
    }
   ],
   "source": [
    "# Dividi il dataset in feature (X) e target (y)\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "# Divisione del dataset: Train, Validation e Test set\n",
    "# 1. Prima divisione: Separiamo il Test set (20%) dal resto (80%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# 2. Seconda divisione: Dell'80% rimanente, prendiamo il 10% per il Validation e il resto per il Train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "# Stampiamo le dimensioni per verificare che tutto sia corretto\n",
    "print(\"Campioni di Training (per allenare il modello): \", X_train.shape[0])\n",
    "print(\"Campioni di Test (per valutare alla fine): \", X_test.shape[0])\n",
    "print(\"Campioni di Validation (per ottimizzare durante il training): \", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversione dei dati da NumPy arrays a PyTorch Tensors\n",
    "# Le reti neurali in PyTorch lavorano con i \"tensori\" (matrici n-dimensionali che possono stare su GPU)\n",
    "\n",
    "# Features (Input): Usiamo float32 perché sono numeri decimali continui\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Target (Output): Usiamo Long (interi) perché CrossEntropyLoss si aspetta \n",
    "# gli indici delle classi (0, 1, 2...), non numeri decimali.\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoader: Creano dei \"pacchetti\" (batch) di dati.\n",
    "# Invece di passare tutti i dati insieme, li passiamo a piccoli gruppi.\n",
    "# Questo aiuta la rete ad imparare meglio e ad usare meno memoria.\n",
    "# Per val e test usiamo un unico grande batch perché non dobbiamo fare backpropagation.\n",
    "val_dataloader = DataLoader(TensorDataset(X_val, y_val), batch_size=y_val.shape[0])\n",
    "test_dataloader = DataLoader(TensorDataset(X_test, y_test), batch_size=y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e708dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, dept=3, hidden_size=64, dropout_prob=0.2):\n",
    "    \"\"\"\n",
    "    Crea dinamicamente una rete neurale in base ai parametri passati.\n",
    "    \n",
    "    Args:\n",
    "        input_size: numero di caratteristiche in ingresso (4 per Iris)\n",
    "        dept (depth): profondità della rete, cioè quanti layer nascosti aggiungere\n",
    "        hidden_size: quanti neuroni mettere in ogni layer nascosto\n",
    "        dropout_prob: probabilità di spegnere neuroni (per evitare overfitting)\n",
    "    \"\"\"\n",
    "    # 1. Primo layer: Connette l'input al primo strato nascosto\n",
    "    model = [nn.Linear(input_size, hidden_size), nn.ReLU() ]\n",
    "    \n",
    "    # 2. Layer intermedi (Hidden): Vengono aggiunti in un ciclo in base a 'dept'\n",
    "    for i in range(dept):\n",
    "        model.append(nn.Linear(hidden_size, hidden_size)) # Connessione lineare\n",
    "        model.append(nn.ReLU())                           # Attivazione non lineare\n",
    "        model.append(nn.Dropout(dropout_prob))            # Regolarizzazione (Dropout)\n",
    "        \n",
    "    # 3. Output layer: Connette l'ultimo layer nascosto alle 3 classi finali\n",
    "    model.append(nn.Linear(hidden_size, 3))\n",
    "    \n",
    "    # nn.Sequential unisce la lista di layer in un unico modello ordinato\n",
    "    return nn.Sequential(*model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  162\n"
     ]
    }
   ],
   "source": [
    "# --- GRID SEARCH SETUP ---\n",
    "# Definiamo le liste di valori da provare per ogni iperparametro\n",
    "hidden_size = [128, 256, 512]       # Neuroni per strato\n",
    "dropout_prob = [0.2, 0.3, 0.4]      # Quanto \"spegnere\" la rete\n",
    "dept = [3, 4, 5]                    # Quanti strati\n",
    "epochs = 200                        # Durata training (fisso)\n",
    "batch_size = [8,16,32]              # Dimensione pacchetto dati\n",
    "learning_rate = [0.001, 0.01]       # Velocità di apprendimento\n",
    "\n",
    "# itertools.product crea il Prodotto Cartesiano:\n",
    "# Genera TUTTE le possibili combinazioni tra queste liste.\n",
    "# Es: (128, 0.2, 3, 8, 0.001), (128, 0.2, 3, 8, 0.01), ...\n",
    "params = product(hidden_size, dropout_prob, dept, batch_size, learning_rate)\n",
    "\n",
    "# Calcoliamo quante combinazioni dovremo testare\n",
    "combinations = len(hidden_size)*len(dropout_prob)*len(dept)*len(batch_size)*len(learning_rate)\n",
    "print(\"Numero totale di configurazioni da testare: \", combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, device, hidden_size=3, dropout_prob=0.2, dept=2, epochs=100, batch_size=32, learning_rate=.001):\n",
    "    \"\"\"\n",
    "    Esegue il training di un singolo modello.\n",
    "    \"\"\"\n",
    "    # LOSS FUNCTION: Usiamo CrossEntropyLoss perché è un problema di Classificazione \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # OPTIMIZER: Adam è l'algoritmo che aggiorna i pesi per minimizzare l'errore\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Liste per salvare lo storico degli errori\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # EARLY STOPPING:\n",
    "    # Serve a fermare il training se il modello smette di migliorare sul validation set.\n",
    "    best_model = None\n",
    "    best_loss = np.inf   # Inizializziamo con infinito\n",
    "    patience = 10        # Quante epoche aspettiamo se non migliora\n",
    "    patience_counter = 0\n",
    "\n",
    "    # --- CICLO DI TRAINING (EPOCHE) ---\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # Mettiamo il modello in modalità training (abilita Dropout, ecc.)\n",
    "        model.train() \n",
    "\n",
    "        # Iteriamo sui batch di dati\n",
    "        for x, y in train_dataloader:\n",
    "            x, y = x.to(device), y.to(device) # Spostiamo dati su GPU/CPU\n",
    "            \n",
    "            optimizer.zero_grad()    # 1. Azzeriamo i gradienti precedenti\n",
    "            y_pred = model(x)        # 2. Forward pass (previsione)\n",
    "            loss = criterion(y_pred, y) # 3. Calcolo errore\n",
    "            loss.backward()          # 4. Backward pass (calcolo gradienti)\n",
    "            optimizer.step()         # 5. Aggiornamento pesi\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Salviamo la loss media di training per questa epoca\n",
    "        train_loss.append(epoch_loss / len(train_dataloader))\n",
    "\n",
    "        # --- VALIDATION ---\n",
    "        # Valutiamo come va il modello su dati che non ha usato per l'allenamento\n",
    "        model.eval() # Modalità valutazione (disabilita Dropout)\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad(): # Disabilita calcolo gradienti (più veloce, meno memoria)\n",
    "            for x, y in val_dataloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                epoch_val_loss += loss.item()\n",
    "        val_loss.append(epoch_val_loss / len(val_dataloader))\n",
    "\n",
    "        # Stampa progressi ogni 10 epoche\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train loss: {train_loss[-1]:.4f}, Val loss: {val_loss[-1]:.4f}, Time: {time.time()-epoch_start:.2f}s')\n",
    "\n",
    "        # --- EARLY STOPPING CHECK ---\n",
    "        # Se l'errore di validazione è il più basso visto finora, salviamo questo modello\n",
    "        if val_loss[-1] < best_loss:\n",
    "            best_loss = val_loss[-1]\n",
    "            best_model = copy.deepcopy(model) # Creiamo una copia esatta del modello attuale\n",
    "            patience_counter = 0 # Resettiamo il contatore\n",
    "        else:\n",
    "            # Se non migliora, incrementiamo il contatore\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                # Se abbiamo aspettato troppo ('patience' epoche), interrompiamo.\n",
    "                print(\"Early stopping...\") \n",
    "                break\n",
    "\n",
    "    print(\"Training terminato in {} epoche. Miglior validation loss: {}\".format(epoch+1, best_loss))\n",
    "\n",
    "    # Restituiamo il miglior modello trovato (non necessariamente l'ultimo)\n",
    "    return best_model, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader, device):\n",
    "    \"\"\"\n",
    "    Valuta il modello finale sul Test Set per ottenere accuracy e predizioni.\n",
    "    \"\"\"\n",
    "    model.eval() # Importante: modalità valutazione\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dataloader:\n",
    "            x , y = x.to(device), y.to(device)\n",
    "            # model(x) restituisce 3 probabilità (logits).\n",
    "            # torch.max(..., 1) ci dice qual è l'indice (0, 1 o 2) con il valore più alto.\n",
    "            # quell'indice è la classe predetta.\n",
    "            output = model(x)\n",
    "            _, predicted = torch.max(output, 1) # Ottieni classe vincente\n",
    "            \n",
    "            y_pred.extend(predicted.cpu().tolist())\n",
    "            y_true.extend(y.cpu().tolist())\n",
    "            \n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0596, Val loss: 0.2149, Time: 0.05s\n",
      "Training in 19 epochs with best val loss: 0.16763661801815033\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.0000\n",
      "\n",
      "Iteration 2/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3572, Val loss: 0.3462, Time: 0.05s\n",
      "Training in 15 epochs with best val loss: 0.1263498067855835\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.8667\n",
      "\n",
      "Iteration 3/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0568, Val loss: 0.3277, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0452, Val loss: 0.5028, Time: 0.04s\n",
      "Training in 26 epochs with best val loss: 0.17021971940994263\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.8667\n",
      "\n",
      "Iteration 4/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4427, Val loss: 0.9819, Time: 0.08s\n",
      "Epoch 20/100, Train loss: 0.1568, Val loss: 0.1125, Time: 0.05s\n",
      "Training in 29 epochs with best val loss: 0.09161197394132614\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.8667\n",
      "\n",
      "Iteration 5/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2464, Val loss: 0.4971, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0960, Val loss: 0.5410, Time: 0.06s\n",
      "Epoch 30/100, Train loss: 0.0389, Val loss: 0.5874, Time: 0.02s\n",
      "Training in 31 epochs with best val loss: 0.21507425606250763\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.8667\n",
      "\n",
      "Iteration 6/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2747, Val loss: 0.5446, Time: 0.04s\n",
      "Training in 16 epochs with best val loss: 0.18275241553783417\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 0.8667\n",
      "\n",
      "Iteration 7/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0281, Val loss: 1.0419, Time: 0.04s\n",
      "Training in 14 epochs with best val loss: 0.2740553915500641\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 0.8667\n",
      "\n",
      "Iteration 8/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3111, Val loss: 0.3080, Time: 0.10s\n",
      "Epoch 20/100, Train loss: 0.3098, Val loss: 0.3560, Time: 0.12s\n",
      "Training in 21 epochs with best val loss: 0.13044871389865875\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 9/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1193, Val loss: 0.5966, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0617, Val loss: 0.6235, Time: 0.02s\n",
      "Training in 24 epochs with best val loss: 0.13756899535655975\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 10/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2007, Val loss: 0.2016, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.1412, Val loss: 0.7943, Time: 0.05s\n",
      "Training in 21 epochs with best val loss: 0.1762385219335556\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 11/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1904, Val loss: 0.3760, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0587, Val loss: 0.5387, Time: 0.01s\n",
      "Epoch 30/100, Train loss: 0.0497, Val loss: 0.7555, Time: 0.02s\n",
      "Training in 34 epochs with best val loss: 0.1411421149969101\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 12/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4917, Val loss: 0.5370, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.3178, Val loss: 0.0652, Time: 0.03s\n",
      "Epoch 30/100, Train loss: 0.2772, Val loss: 0.6894, Time: 0.13s\n",
      "Training in 30 epochs with best val loss: 0.06523556262254715\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 13/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0499, Val loss: 0.1518, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.1211, Val loss: 0.6231, Time: 0.05s\n",
      "Training in 20 epochs with best val loss: 0.15180626511573792\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 14/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4115, Val loss: 0.4917, Time: 0.22s\n",
      "Epoch 20/100, Train loss: 0.3135, Val loss: 0.3932, Time: 0.04s\n",
      "Epoch 30/100, Train loss: 0.1789, Val loss: 0.4050, Time: 0.13s\n",
      "Training in 34 epochs with best val loss: 0.16173438727855682\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 15/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1514, Val loss: 0.3069, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.2021, Val loss: 1.2275, Time: 0.10s\n",
      "Training in 21 epochs with best val loss: 0.11175315827131271\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 16/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2921, Val loss: 1.4063, Time: 0.09s\n",
      "Epoch 20/100, Train loss: 0.1230, Val loss: 0.2107, Time: 0.06s\n",
      "Training in 26 epochs with best val loss: 0.09016799181699753\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 17/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2276, Val loss: 0.2399, Time: 0.06s\n",
      "Epoch 20/100, Train loss: 0.0578, Val loss: 0.4682, Time: 0.04s\n",
      "Training in 27 epochs with best val loss: 0.10920674353837967\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 18/162\n",
      "hidden_size: 128, dropout_prob: 0.2, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4112, Val loss: 0.4737, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.2081, Val loss: 0.3155, Time: 0.03s\n",
      "Epoch 30/100, Train loss: 0.1471, Val loss: 0.4746, Time: 0.10s\n",
      "Training in 33 epochs with best val loss: 0.09080047160387039\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 19/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1051, Val loss: 0.6714, Time: 0.04s\n",
      "Training in 18 epochs with best val loss: 0.2034572958946228\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 20/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 1.2742, Val loss: 0.5013, Time: 0.03s\n",
      "Training in 15 epochs with best val loss: 0.2461634874343872\n",
      "Test Accuracy: 1.0000 - Best Test Accuracy: 0.9000\n",
      "\n",
      "Iteration 21/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1020, Val loss: 0.1903, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0324, Val loss: 0.6120, Time: 0.02s\n",
      "Training in 20 epochs with best val loss: 0.19031839072704315\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 22/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3354, Val loss: 0.3310, Time: 0.04s\n",
      "Training in 19 epochs with best val loss: 0.12557139992713928\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 23/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2606, Val loss: 0.3394, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0871, Val loss: 0.5698, Time: 0.00s\n",
      "Training in 28 epochs with best val loss: 0.1676466315984726\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 24/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0320, Val loss: 0.2109, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0382, Val loss: 0.9924, Time: 0.03s\n",
      "Training in 20 epochs with best val loss: 0.21090799570083618\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 25/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1774, Val loss: 0.8513, Time: 0.19s\n",
      "Training in 14 epochs with best val loss: 0.18298350274562836\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 26/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1355, Val loss: 0.5464, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.1503, Val loss: 0.8717, Time: 0.06s\n",
      "Training in 29 epochs with best val loss: 0.1558864861726761\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 27/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1471, Val loss: 0.1938, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.0679, Val loss: 0.3253, Time: 0.04s\n",
      "Training in 27 epochs with best val loss: 0.17265202105045319\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 28/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2119, Val loss: 0.1003, Time: 0.04s\n",
      "Training in 19 epochs with best val loss: 0.08732610940933228\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 29/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1795, Val loss: 0.5726, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0620, Val loss: 0.5779, Time: 0.05s\n",
      "Training in 25 epochs with best val loss: 0.13911795616149902\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 30/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1892, Val loss: 0.2797, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0696, Val loss: 0.8809, Time: 0.02s\n",
      "Training in 29 epochs with best val loss: 0.21921588480472565\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 31/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1366, Val loss: 0.1449, Time: 0.05s\n",
      "Training in 19 epochs with best val loss: 0.14439402520656586\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 32/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2618, Val loss: 0.4166, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.1210, Val loss: 1.0652, Time: 0.05s\n",
      "Training in 25 epochs with best val loss: 0.0358632393181324\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 33/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0800, Val loss: 0.1539, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0801, Val loss: 1.0770, Time: 0.02s\n",
      "Training in 20 epochs with best val loss: 0.15389521420001984\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 34/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2202, Val loss: 0.7268, Time: 0.08s\n",
      "Epoch 20/100, Train loss: 0.0355, Val loss: 0.8916, Time: 0.08s\n",
      "Epoch 30/100, Train loss: 0.0918, Val loss: 1.0304, Time: 0.07s\n",
      "Training in 34 epochs with best val loss: 0.10051131993532181\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 35/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2069, Val loss: 0.4083, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.1177, Val loss: 0.6178, Time: 0.01s\n",
      "Training in 27 epochs with best val loss: 0.10971490293741226\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 36/162\n",
      "hidden_size: 128, dropout_prob: 0.3, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.8084, Val loss: 0.5006, Time: 0.01s\n",
      "Epoch 20/100, Train loss: 0.2801, Val loss: 0.1997, Time: 0.02s\n",
      "Epoch 30/100, Train loss: 0.5670, Val loss: 0.5340, Time: 0.01s\n",
      "Epoch 40/100, Train loss: 0.0490, Val loss: 1.2408, Time: 0.01s\n",
      "Training in 42 epochs with best val loss: 0.1402694135904312\n",
      "Test Accuracy: 1.0000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 37/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1419, Val loss: 0.1641, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0369, Val loss: 0.8194, Time: 0.02s\n",
      "Training in 20 epochs with best val loss: 0.16408362984657288\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 38/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0770, Val loss: 0.5215, Time: 0.04s\n",
      "Training in 15 epochs with best val loss: 0.3543573319911957\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 39/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1216, Val loss: 0.3254, Time: 0.09s\n",
      "Epoch 20/100, Train loss: 0.0388, Val loss: 0.5690, Time: 0.01s\n",
      "Training in 22 epochs with best val loss: 0.21121852099895477\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 40/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1737, Val loss: 0.3855, Time: 0.03s\n",
      "Training in 15 epochs with best val loss: 0.09684306383132935\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 41/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2056, Val loss: 0.2511, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0552, Val loss: 0.6330, Time: 0.03s\n",
      "Training in 22 epochs with best val loss: 0.20844216644763947\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 42/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3338, Val loss: 0.1243, Time: 0.01s\n",
      "Epoch 20/100, Train loss: 0.0990, Val loss: 0.0668, Time: 0.02s\n",
      "Epoch 30/100, Train loss: 0.0716, Val loss: 0.7820, Time: 0.01s\n",
      "Training in 30 epochs with best val loss: 0.06677884608507156\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 43/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0782, Val loss: 0.2970, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0704, Val loss: 0.3676, Time: 0.05s\n",
      "Training in 21 epochs with best val loss: 0.11818104982376099\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 44/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0550, Val loss: 0.2014, Time: 0.06s\n",
      "Epoch 20/100, Train loss: 0.1569, Val loss: 0.9228, Time: 0.11s\n",
      "Training in 20 epochs with best val loss: 0.20144790410995483\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 45/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.3122, Val loss: 0.5899, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.0777, Val loss: 0.6856, Time: 0.01s\n",
      "Epoch 30/100, Train loss: 0.0548, Val loss: 0.5533, Time: 0.05s\n",
      "Training in 32 epochs with best val loss: 0.17169691622257233\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 46/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0532, Val loss: 0.5132, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0754, Val loss: 0.3817, Time: 0.06s\n",
      "Training in 28 epochs with best val loss: 0.04168674722313881\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 47/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2359, Val loss: 0.3550, Time: 0.01s\n",
      "Epoch 20/100, Train loss: 0.0612, Val loss: 0.3049, Time: 0.02s\n",
      "Training in 26 epochs with best val loss: 0.13217920064926147\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 48/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1058, Val loss: 0.8941, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0467, Val loss: 0.8124, Time: 0.02s\n",
      "Training in 27 epochs with best val loss: 0.051190540194511414\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 49/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1760, Val loss: 0.3831, Time: 0.06s\n",
      "Epoch 20/100, Train loss: 0.0632, Val loss: 0.7797, Time: 0.07s\n",
      "Training in 26 epochs with best val loss: 0.07766885310411453\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 50/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4474, Val loss: 0.5183, Time: 0.12s\n",
      "Epoch 20/100, Train loss: 0.4712, Val loss: 0.5026, Time: 0.09s\n",
      "Training in 28 epochs with best val loss: 0.10760387033224106\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 51/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1559, Val loss: 0.7070, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.1017, Val loss: 0.2996, Time: 0.05s\n",
      "Training in 25 epochs with best val loss: 0.11647634953260422\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 52/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3381, Val loss: 0.3605, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0918, Val loss: 0.3675, Time: 0.10s\n",
      "Training in 26 epochs with best val loss: 0.08944285660982132\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 53/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2209, Val loss: 0.5047, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.0987, Val loss: 0.5632, Time: 0.03s\n",
      "Epoch 30/100, Train loss: 0.0647, Val loss: 0.2953, Time: 0.03s\n",
      "Training in 35 epochs with best val loss: 0.09970387071371078\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 54/162\n",
      "hidden_size: 128, dropout_prob: 0.4, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3663, Val loss: 0.3872, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0939, Val loss: 0.5642, Time: 0.02s\n",
      "Training in 26 epochs with best val loss: 0.17254208028316498\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 55/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0979, Val loss: 0.8743, Time: 0.21s\n",
      "Epoch 20/100, Train loss: 0.0818, Val loss: 1.0021, Time: 0.06s\n",
      "Training in 24 epochs with best val loss: 0.11269386857748032\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 56/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4628, Val loss: 0.4948, Time: 0.10s\n",
      "Training in 13 epochs with best val loss: 0.4520668089389801\n",
      "Test Accuracy: 0.6333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 57/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0251, Val loss: 0.8134, Time: 0.11s\n",
      "Epoch 20/100, Train loss: 0.0977, Val loss: 0.2997, Time: 0.05s\n",
      "Training in 27 epochs with best val loss: 0.11693048477172852\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 58/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1301, Val loss: 0.5120, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.1355, Val loss: 0.3036, Time: 0.09s\n",
      "Training in 23 epochs with best val loss: 0.03647010773420334\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 59/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1122, Val loss: 0.5389, Time: 0.02s\n",
      "Training in 17 epochs with best val loss: 0.1604483425617218\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 60/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2430, Val loss: 2.8255, Time: 0.01s\n",
      "Epoch 20/100, Train loss: 0.0089, Val loss: 1.1400, Time: 0.04s\n",
      "Training in 21 epochs with best val loss: 0.06915778666734695\n",
      "Test Accuracy: 0.8000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 61/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0915, Val loss: 0.5122, Time: 0.08s\n",
      "Training in 14 epochs with best val loss: 0.4066602289676666\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 62/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3842, Val loss: 1.9109, Time: 0.11s\n",
      "Epoch 20/100, Train loss: 0.1533, Val loss: 1.3621, Time: 0.09s\n",
      "Training in 24 epochs with best val loss: 0.08058512955904007\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 63/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2048, Val loss: 0.5189, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.2298, Val loss: 0.3894, Time: 0.07s\n",
      "Training in 24 epochs with best val loss: 0.15225014090538025\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 64/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4093, Val loss: 0.4583, Time: 0.06s\n",
      "Epoch 20/100, Train loss: 0.1210, Val loss: 1.2420, Time: 0.05s\n",
      "Training in 26 epochs with best val loss: 0.09270785003900528\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 65/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1903, Val loss: 0.2204, Time: 0.03s\n",
      "Training in 17 epochs with best val loss: 0.2165563553571701\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 66/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4063, Val loss: 0.4246, Time: 0.30s\n",
      "Epoch 20/100, Train loss: 0.0417, Val loss: 0.9889, Time: 0.03s\n",
      "Training in 24 epochs with best val loss: 0.12602190673351288\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 67/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1603, Val loss: 0.1746, Time: 0.06s\n",
      "Epoch 20/100, Train loss: 0.1275, Val loss: 0.7017, Time: 0.11s\n",
      "Training in 29 epochs with best val loss: 0.0970861092209816\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 68/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3475, Val loss: 0.3993, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.3193, Val loss: 0.7073, Time: 0.13s\n",
      "Epoch 30/100, Train loss: 0.2795, Val loss: 0.3102, Time: 0.07s\n",
      "Training in 36 epochs with best val loss: 0.03864072263240814\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 69/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0863, Val loss: 0.2940, Time: 0.06s\n",
      "Training in 16 epochs with best val loss: 0.15074002742767334\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 70/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.7990, Val loss: 0.4999, Time: 0.04s\n",
      "Training in 19 epochs with best val loss: 0.34288468956947327\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 71/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0639, Val loss: 0.1717, Time: 0.20s\n",
      "Epoch 20/100, Train loss: 0.2021, Val loss: 1.1524, Time: 0.02s\n",
      "Training in 20 epochs with best val loss: 0.17172236740589142\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 72/162\n",
      "hidden_size: 256, dropout_prob: 0.2, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4262, Val loss: 0.4729, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.3982, Val loss: 0.3597, Time: 0.03s\n",
      "Epoch 30/100, Train loss: 0.3360, Val loss: 0.3539, Time: 0.03s\n",
      "Training in 38 epochs with best val loss: 0.13532069325447083\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 73/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0948, Val loss: 0.1411, Time: 0.06s\n",
      "Epoch 20/100, Train loss: 0.0303, Val loss: 0.4808, Time: 0.14s\n",
      "Training in 20 epochs with best val loss: 0.1410706788301468\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 74/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0409, Val loss: 0.2902, Time: 0.16s\n",
      "Training in 15 epochs with best val loss: 0.10154645889997482\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 75/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0371, Val loss: 0.5564, Time: 0.12s\n",
      "Training in 14 epochs with best val loss: 0.3182489275932312\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 76/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2198, Val loss: 0.4490, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.0224, Val loss: 0.9487, Time: 0.03s\n",
      "Training in 25 epochs with best val loss: 0.025317097082734108\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 77/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0829, Val loss: 0.2868, Time: 0.18s\n",
      "Training in 17 epochs with best val loss: 0.2545156180858612\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 78/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2633, Val loss: 0.1302, Time: 0.01s\n",
      "Epoch 20/100, Train loss: 0.2753, Val loss: 0.6129, Time: 0.01s\n",
      "Training in 20 epochs with best val loss: 0.13016101717948914\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 79/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1023, Val loss: 0.4614, Time: 0.08s\n",
      "Training in 16 epochs with best val loss: 0.160322368144989\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 80/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0396, Val loss: 0.4273, Time: 0.07s\n",
      "Training in 13 epochs with best val loss: 0.051660019904375076\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 81/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0933, Val loss: 0.4676, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0659, Val loss: 0.3832, Time: 0.06s\n",
      "Training in 26 epochs with best val loss: 0.10614186525344849\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 82/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.5707, Val loss: 0.4930, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0390, Val loss: 0.3657, Time: 0.03s\n",
      "Epoch 30/100, Train loss: 0.1576, Val loss: 0.4075, Time: 0.03s\n",
      "Training in 34 epochs with best val loss: 0.11338778585195541\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 83/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2241, Val loss: 0.6795, Time: 0.02s\n",
      "Training in 19 epochs with best val loss: 0.19477039575576782\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 84/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2644, Val loss: 0.5217, Time: 0.02s\n",
      "Epoch 20/100, Train loss: 0.0414, Val loss: 0.5619, Time: 0.09s\n",
      "Training in 28 epochs with best val loss: 0.04813575744628906\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 85/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2312, Val loss: 0.3528, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.4127, Val loss: 0.0869, Time: 0.12s\n",
      "Training in 24 epochs with best val loss: 0.05222364887595177\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 86/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.6955, Val loss: 0.5021, Time: 0.28s\n",
      "Epoch 20/100, Train loss: 0.0589, Val loss: 0.1465, Time: 0.18s\n",
      "Epoch 30/100, Train loss: 0.2605, Val loss: 1.6013, Time: 0.44s\n",
      "Training in 30 epochs with best val loss: 0.14653663337230682\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 87/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0771, Val loss: 0.9611, Time: 0.22s\n",
      "Epoch 20/100, Train loss: 0.0754, Val loss: 0.8171, Time: 0.14s\n",
      "Training in 26 epochs with best val loss: 0.15152780711650848\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 88/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4287, Val loss: 0.5181, Time: 0.10s\n",
      "Epoch 20/100, Train loss: 0.1990, Val loss: 0.4573, Time: 0.07s\n",
      "Training in 27 epochs with best val loss: 0.23089410364627838\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 89/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2958, Val loss: 0.1555, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.0415, Val loss: 0.3261, Time: 0.10s\n",
      "Training in 20 epochs with best val loss: 0.15554766356945038\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 90/162\n",
      "hidden_size: 256, dropout_prob: 0.3, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1306, Val loss: 1.1526, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.4501, Val loss: 0.4760, Time: 0.04s\n",
      "Training in 27 epochs with best val loss: 0.14768601953983307\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 91/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0570, Val loss: 0.7213, Time: 0.08s\n",
      "Training in 13 epochs with best val loss: 0.28461867570877075\n",
      "Test Accuracy: 0.9667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 92/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1138, Val loss: 0.9493, Time: 0.08s\n",
      "Training in 14 epochs with best val loss: 0.2009623795747757\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 93/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1232, Val loss: 0.4228, Time: 0.08s\n",
      "Training in 18 epochs with best val loss: 0.14359693229198456\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 94/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2013, Val loss: 0.9793, Time: 0.15s\n",
      "Epoch 20/100, Train loss: 0.1858, Val loss: 1.1227, Time: 0.09s\n",
      "Training in 23 epochs with best val loss: 0.07709182053804398\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 95/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1173, Val loss: 0.4259, Time: 0.03s\n",
      "Training in 17 epochs with best val loss: 0.2512931525707245\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 96/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1693, Val loss: 0.2235, Time: 0.03s\n",
      "Training in 15 epochs with best val loss: 0.16184817254543304\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 97/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.3012, Val loss: 0.1722, Time: 0.10s\n",
      "Epoch 20/100, Train loss: 0.1051, Val loss: 0.5080, Time: 0.12s\n",
      "Training in 20 epochs with best val loss: 0.17223556339740753\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 98/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1617, Val loss: 1.6610, Time: 0.12s\n",
      "Training in 14 epochs with best val loss: 0.08402848243713379\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 99/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0298, Val loss: 1.1060, Time: 0.11s\n",
      "Epoch 20/100, Train loss: 0.0354, Val loss: 0.2675, Time: 0.06s\n",
      "Training in 23 epochs with best val loss: 0.11667394638061523\n",
      "Test Accuracy: 0.8000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 100/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0893, Val loss: 0.5470, Time: 0.07s\n",
      "Training in 15 epochs with best val loss: 0.12220367789268494\n",
      "Test Accuracy: 0.8000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 101/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0381, Val loss: 0.1602, Time: 0.01s\n",
      "Epoch 20/100, Train loss: 0.0678, Val loss: 0.2309, Time: 0.06s\n",
      "Training in 20 epochs with best val loss: 0.16020743548870087\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 102/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2616, Val loss: 0.7721, Time: 0.04s\n",
      "Training in 19 epochs with best val loss: 0.21758747100830078\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 103/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1276, Val loss: 0.2581, Time: 0.12s\n",
      "Training in 17 epochs with best val loss: 0.21305091679096222\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 104/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3314, Val loss: 0.3876, Time: 0.15s\n",
      "Epoch 20/100, Train loss: 0.1617, Val loss: 0.4447, Time: 0.19s\n",
      "Training in 21 epochs with best val loss: 0.2662712335586548\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 105/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0874, Val loss: 1.0095, Time: 0.08s\n",
      "Epoch 20/100, Train loss: 0.0265, Val loss: 0.8291, Time: 0.09s\n",
      "Training in 21 epochs with best val loss: 0.15183724462985992\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 106/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0929, Val loss: 0.1774, Time: 0.10s\n",
      "Epoch 20/100, Train loss: 0.2402, Val loss: 2.6554, Time: 0.09s\n",
      "Training in 20 epochs with best val loss: 0.17738337814807892\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 107/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.4291, Val loss: 0.5729, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.1737, Val loss: 0.6668, Time: 0.07s\n",
      "Training in 29 epochs with best val loss: 0.22821331024169922\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 108/162\n",
      "hidden_size: 256, dropout_prob: 0.4, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4137, Val loss: 0.5996, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.3095, Val loss: 0.3145, Time: 0.04s\n",
      "Epoch 30/100, Train loss: 0.0985, Val loss: 0.2499, Time: 0.05s\n",
      "Training in 33 epochs with best val loss: 0.16577069461345673\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 109/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0609, Val loss: 0.2845, Time: 0.12s\n",
      "Training in 15 epochs with best val loss: 0.14425592124462128\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 110/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3549, Val loss: 0.2410, Time: 0.10s\n",
      "Training in 18 epochs with best val loss: 0.10400852560997009\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 111/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1340, Val loss: 0.4203, Time: 0.12s\n",
      "Epoch 20/100, Train loss: 0.0416, Val loss: 0.4032, Time: 0.10s\n",
      "Training in 25 epochs with best val loss: 0.1493852734565735\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 112/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0482, Val loss: 1.1547, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.0220, Val loss: 0.5422, Time: 0.06s\n",
      "Epoch 30/100, Train loss: 0.0556, Val loss: 1.0339, Time: 0.09s\n",
      "Training in 33 epochs with best val loss: 0.011846174485981464\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 113/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1763, Val loss: 0.2734, Time: 0.05s\n",
      "Training in 16 epochs with best val loss: 0.1708243489265442\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 114/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2460, Val loss: 0.7700, Time: 0.03s\n",
      "Training in 17 epochs with best val loss: 0.23115132749080658\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 115/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.3014, Val loss: 0.4891, Time: 0.12s\n",
      "Training in 13 epochs with best val loss: 0.4451517164707184\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 116/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1647, Val loss: 1.6183, Time: 0.27s\n",
      "Epoch 20/100, Train loss: 0.4680, Val loss: 1.2157, Time: 0.19s\n",
      "Training in 21 epochs with best val loss: 0.10235434770584106\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 117/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0719, Val loss: 0.8598, Time: 0.10s\n",
      "Training in 18 epochs with best val loss: 0.12668530642986298\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 118/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 1.3471, Val loss: 0.5538, Time: 0.09s\n",
      "Epoch 20/100, Train loss: 0.0436, Val loss: 1.2288, Time: 0.08s\n",
      "Training in 25 epochs with best val loss: 0.13145960867404938\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 119/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0532, Val loss: 0.6351, Time: 0.04s\n",
      "Training in 16 epochs with best val loss: 0.25426068902015686\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 120/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2393, Val loss: 0.1729, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0317, Val loss: 2.7167, Time: 0.06s\n",
      "Training in 22 epochs with best val loss: 0.17219553887844086\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 121/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1414, Val loss: 0.5670, Time: 0.13s\n",
      "Epoch 20/100, Train loss: 0.1290, Val loss: 0.6493, Time: 0.17s\n",
      "Training in 24 epochs with best val loss: 0.11181378364562988\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 122/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.7809, Val loss: 0.4953, Time: 0.29s\n",
      "Epoch 20/100, Train loss: 0.3876, Val loss: 0.4865, Time: 0.16s\n",
      "Training in 22 epochs with best val loss: 0.4735681116580963\n",
      "Test Accuracy: 0.7333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 123/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1498, Val loss: 0.1094, Time: 0.14s\n",
      "Epoch 20/100, Train loss: 0.1217, Val loss: 0.8856, Time: 0.16s\n",
      "Training in 20 epochs with best val loss: 0.1093933954834938\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 124/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0533, Val loss: 1.2725, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.2273, Val loss: 1.2924, Time: 0.14s\n",
      "Training in 21 epochs with best val loss: 0.12834776937961578\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 125/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2237, Val loss: 0.8064, Time: 0.02s\n",
      "Training in 19 epochs with best val loss: 0.2225624918937683\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 126/162\n",
      "hidden_size: 512, dropout_prob: 0.2, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4681, Val loss: 0.5080, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.3640, Val loss: 0.5066, Time: 0.05s\n",
      "Training in 26 epochs with best val loss: 0.14431346952915192\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 127/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0507, Val loss: 0.9536, Time: 0.11s\n",
      "Epoch 20/100, Train loss: 0.0261, Val loss: 0.4977, Time: 0.11s\n",
      "Epoch 30/100, Train loss: 0.1551, Val loss: 0.6960, Time: 0.11s\n",
      "Training in 39 epochs with best val loss: 0.0717158243060112\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 128/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0411, Val loss: 0.5488, Time: 0.18s\n",
      "Training in 19 epochs with best val loss: 0.28053754568099976\n",
      "Test Accuracy: 1.0000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 129/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0839, Val loss: 0.2397, Time: 0.05s\n",
      "Training in 16 epochs with best val loss: 0.2273399382829666\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 130/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1266, Val loss: 0.2849, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.0563, Val loss: 0.4980, Time: 0.09s\n",
      "Training in 25 epochs with best val loss: 0.10949239879846573\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 131/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0994, Val loss: 0.2118, Time: 0.04s\n",
      "Epoch 20/100, Train loss: 0.0249, Val loss: 0.8314, Time: 0.05s\n",
      "Training in 22 epochs with best val loss: 0.15078316628932953\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 132/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.0406, Val loss: 2.3270, Time: 0.03s\n",
      "Epoch 20/100, Train loss: 0.0313, Val loss: 1.1620, Time: 0.03s\n",
      "Training in 25 epochs with best val loss: 0.1708468198776245\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 133/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0253, Val loss: 0.7522, Time: 0.23s\n",
      "Training in 18 epochs with best val loss: 0.18928124010562897\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 134/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1601, Val loss: 0.2241, Time: 0.15s\n",
      "Epoch 20/100, Train loss: 0.4571, Val loss: 0.4307, Time: 0.19s\n",
      "Training in 20 epochs with best val loss: 0.22406478226184845\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 135/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1823, Val loss: 1.2030, Time: 0.08s\n",
      "Training in 14 epochs with best val loss: 0.19204847514629364\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 136/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1512, Val loss: 0.2510, Time: 0.10s\n",
      "Epoch 20/100, Train loss: 0.1746, Val loss: 0.1019, Time: 0.13s\n",
      "Epoch 30/100, Train loss: 0.5122, Val loss: 0.3163, Time: 0.12s\n",
      "Training in 37 epochs with best val loss: 0.04330308362841606\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 137/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1393, Val loss: 0.2502, Time: 0.05s\n",
      "Epoch 20/100, Train loss: 0.1555, Val loss: 0.8889, Time: 0.05s\n",
      "Training in 27 epochs with best val loss: 0.07361314445734024\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 138/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2413, Val loss: 0.3096, Time: 0.09s\n",
      "Epoch 20/100, Train loss: 0.5584, Val loss: 0.3368, Time: 0.09s\n",
      "Training in 21 epochs with best val loss: 0.1398238241672516\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 139/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1470, Val loss: 0.2363, Time: 0.22s\n",
      "Epoch 20/100, Train loss: 0.0414, Val loss: 1.1399, Time: 0.30s\n",
      "Training in 23 epochs with best val loss: 0.17676474153995514\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 140/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4285, Val loss: 0.4895, Time: 0.19s\n",
      "Epoch 20/100, Train loss: 0.5292, Val loss: 0.6316, Time: 0.24s\n",
      "Training in 27 epochs with best val loss: 0.17174899578094482\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 141/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1400, Val loss: 0.5497, Time: 0.08s\n",
      "Epoch 20/100, Train loss: 0.3153, Val loss: 0.9451, Time: 0.16s\n",
      "Epoch 30/100, Train loss: 0.0356, Val loss: 0.4952, Time: 0.08s\n",
      "Training in 31 epochs with best val loss: 0.1658376157283783\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 142/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4765, Val loss: 0.5461, Time: 0.11s\n",
      "Epoch 20/100, Train loss: 0.2136, Val loss: 1.4328, Time: 0.09s\n",
      "Training in 26 epochs with best val loss: 0.12955762445926666\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 143/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1539, Val loss: 0.1953, Time: 0.11s\n",
      "Epoch 20/100, Train loss: 0.1049, Val loss: 0.1334, Time: 0.07s\n",
      "Training in 22 epochs with best val loss: 0.10259539633989334\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 144/162\n",
      "hidden_size: 512, dropout_prob: 0.3, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4151, Val loss: 0.4947, Time: 0.09s\n",
      "Epoch 20/100, Train loss: 1.3762, Val loss: 0.7475, Time: 0.15s\n",
      "Training in 26 epochs with best val loss: 0.367898553609848\n",
      "Test Accuracy: 0.9667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 145/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 3, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0192, Val loss: 0.6537, Time: 0.21s\n",
      "Epoch 20/100, Train loss: 0.0307, Val loss: 1.6275, Time: 0.15s\n",
      "Training in 21 epochs with best val loss: 0.08652663975954056\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 146/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 3, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1173, Val loss: 0.0988, Time: 0.12s\n",
      "Epoch 20/100, Train loss: 0.0107, Val loss: 0.7462, Time: 0.16s\n",
      "Training in 20 epochs with best val loss: 0.09877102822065353\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 147/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 3, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0241, Val loss: 0.6735, Time: 0.06s\n",
      "Training in 15 epochs with best val loss: 0.17271138727664948\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 148/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 3, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3181, Val loss: 0.1743, Time: 0.04s\n",
      "Training in 16 epochs with best val loss: 0.12214621901512146\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 149/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 3, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0603, Val loss: 0.2960, Time: 0.05s\n",
      "Training in 18 epochs with best val loss: 0.15166524052619934\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 150/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 3, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.1385, Val loss: 0.2786, Time: 0.08s\n",
      "Epoch 20/100, Train loss: 0.1373, Val loss: 0.3827, Time: 0.09s\n",
      "Training in 29 epochs with best val loss: 0.23980700969696045\n",
      "Test Accuracy: 0.9000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 151/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 4, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1657, Val loss: 0.2215, Time: 0.16s\n",
      "Epoch 20/100, Train loss: 0.1445, Val loss: 0.8718, Time: 0.20s\n",
      "Training in 22 epochs with best val loss: 0.1455204039812088\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 152/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 4, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.7639, Val loss: 0.7202, Time: 0.16s\n",
      "Training in 19 epochs with best val loss: 0.32002392411231995\n",
      "Test Accuracy: 1.0000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 153/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 4, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.0253, Val loss: 0.6171, Time: 0.13s\n",
      "Training in 14 epochs with best val loss: 0.14092741906642914\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 154/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 4, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.2323, Val loss: 0.1216, Time: 0.08s\n",
      "Epoch 20/100, Train loss: 0.1500, Val loss: 0.9297, Time: 0.08s\n",
      "Training in 20 epochs with best val loss: 0.12158653140068054\n",
      "Test Accuracy: 0.8000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 155/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 4, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1471, Val loss: 0.6216, Time: 0.07s\n",
      "Training in 19 epochs with best val loss: 0.17288054525852203\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 156/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 4, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4367, Val loss: 0.5235, Time: 0.11s\n",
      "Training in 16 epochs with best val loss: 0.1697259098291397\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 157/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 5, batch_size: 8, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.3138, Val loss: 0.3984, Time: 0.25s\n",
      "Training in 17 epochs with best val loss: 0.129212886095047\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 158/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 5, batch_size: 8, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.4908, Val loss: 0.5060, Time: 0.29s\n",
      "Training in 17 epochs with best val loss: 0.43131181597709656\n",
      "Test Accuracy: 0.9333 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 159/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 5, batch_size: 16, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.2088, Val loss: 0.3380, Time: 0.17s\n",
      "Epoch 20/100, Train loss: 0.5457, Val loss: 0.5312, Time: 0.14s\n",
      "Training in 28 epochs with best val loss: 0.07195774465799332\n",
      "Test Accuracy: 0.8000 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 160/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 5, batch_size: 16, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.3831, Val loss: 0.4245, Time: 0.18s\n",
      "Epoch 20/100, Train loss: 0.4423, Val loss: 0.4823, Time: 0.09s\n",
      "Training in 22 epochs with best val loss: 0.21687476336956024\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 161/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 5, batch_size: 32, learning_rate: 0.001\n",
      "Epoch 10/100, Train loss: 0.1461, Val loss: 0.5917, Time: 0.07s\n",
      "Epoch 20/100, Train loss: 0.0596, Val loss: 0.8335, Time: 0.05s\n",
      "Training in 29 epochs with best val loss: 0.18372952938079834\n",
      "Test Accuracy: 0.8667 - Best Test Accuracy: 1.0000\n",
      "\n",
      "Iteration 162/162\n",
      "hidden_size: 512, dropout_prob: 0.4, dept: 5, batch_size: 32, learning_rate: 0.01\n",
      "Epoch 10/100, Train loss: 0.5187, Val loss: 0.5292, Time: 0.12s\n",
      "Epoch 20/100, Train loss: 0.1553, Val loss: 0.2690, Time: 0.13s\n",
      "Epoch 30/100, Train loss: 0.8889, Val loss: 0.6837, Time: 0.06s\n",
      "Training in 32 epochs with best val loss: 0.12967045605182648\n",
      "Test Accuracy: 0.8333 - Best Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- CICLO PRINCIPALE GRID SEARCH ---\n",
    "# Qui proviamo ad allenare una rete diversa per ogni combinazione di iperparametri\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "iter_count = 0 \n",
    "\n",
    "# Iteriamo su tutte le combinazioni generate da itertools.product\n",
    "for hidden_size, dropout_prob, dept, batch_size, learning_rate in params:\n",
    "    iter_count += 1\n",
    "    print(f'\\n--- Iterazione {iter_count}/{combinations} ---')\n",
    "    print(f'Configurazione: Hidden={hidden_size}, Drop={dropout_prob}, Dept={dept}, Batch={batch_size}, LR={learning_rate}')\n",
    "\n",
    "    # 1. Creiamo un NUOVO modello con questa specifica configurazione\n",
    "    model = get_model(X_train.shape[1], dept=dept, hidden_size=hidden_size, dropout_prob=dropout_prob)\n",
    "    \n",
    "    # Creiamo il DataLoader specifico (perché il batch_size cambia)\n",
    "    train_dataloader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Dizionario utile per salvare la configurazione corrente\n",
    "    config = {\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout_prob': dropout_prob,\n",
    "        'dept': dept,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "\n",
    "    # 2. Alleniamo il modello e otteniamo la versione migliore (grazie all'early stopping)\n",
    "    trained_model, train_loss, val_loss = train(model, train_dataloader, val_dataloader, device, **config)\n",
    "\n",
    "    # 3. Testiamo il modello allenato sul Test Set\n",
    "    y_pred, y_true = test_model(trained_model, test_dataloader, device)\n",
    "    test_acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'Test Accuracy: {test_acc:.4f} (Migliore attuale: {best_accuracy:.4f})')\n",
    "\n",
    "    # 4. Confronto: È questo il modello migliore visto finora?\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "        best_model = copy.deepcopy(trained_model) # Salviamo una copia\n",
    "        best_config = config\n",
    "        print(\"🏆 NUOVO RECORD!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbcb6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'hidden_size': 128, 'dropout_prob': 0.3, 'dept': 3, 'batch_size': 8, 'learning_rate': 0.01}\n",
      "Best accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Best config: {best_config}')\n",
    "print(f'Best accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1379e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = test_model(best_model, test_dataloader, device)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f'Final Accuracy score: {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
